import requests
import os

TOKEN_FILE = 'token.txt'

def get_token_from_file():
    if os.path.exists(TOKEN_FILE):
        with open(TOKEN_FILE, 'r') as f:
            token = f.read().strip()
            if token:
                return token
    return None

def login_and_save_token(username, password):
    url = 'https://hazy-eng.apifree.site/api/token'
    headers = {'accept': 'application/json, text/plain, */*'}
    data = {'username': username, 'password': password}
    response = requests.post(url, headers=headers, data=data)
    if response.status_code == 200:
        token = response.json().get('access_token')
        if token:
            with open(TOKEN_FILE, 'w') as f:
                f.write(token)
            return token
    print('Lá»—i khi láº¥y token hoáº·c Ä‘Äƒng nháº­p khÃ´ng thÃ nh cÃ´ng')
    return None

def get_token(username, password):
    token = get_token_from_file()
    if token:
        return token
    return login_and_save_token(username, password)

def lookup_word(word, token):
    url = f'https://hazy-eng.apifree.site/api/lookup?word={word}'
    headers = {'Authorization': f'Bearer {token}'}
    response = requests.post(url, headers=headers)
    if response.status_code != 200:
        print(f'KhÃ´ng tÃ¬m tháº¥y tá»« hoáº·c cÃ³ lá»—i khi truy cáº­p API. Status code: {response.status_code}')
        print('Response:', response.text)
        return
    data = response.json()
    print(f"ğŸ”¤ Tá»«: {data.get('word', word).upper()}")
    print(f"ğŸ‡»ğŸ‡³ NghÄ©a tiáº¿ng Viá»‡t: {data.get('vietnamese_word', 'KhÃ´ng cÃ³')}")
    wiki_url = data.get('source_urls', [''])[0]
    if wiki_url:
        print(f"ğŸ“š Link Wiktionary: {wiki_url}")
    phonetics = data.get('phonetics', [])
    if phonetics:
        print("\nğŸ”Š PhÃ¡t Ã¢m:")
        for p in phonetics:
            if p.get('text'):
                print(f" ğŸ“ {p['text']}")
            if p.get('audio'):
                print(f" ğŸµ Audio: {p['audio']}")
    meanings = data.get('meanings', [])
    if meanings:
        print("\nğŸ“– CÃ¡c nghÄ©a:")
        for m in meanings:
            pos = m.get('part_of_speech', 'KhÃ´ng rÃµ')
            print(f" ğŸ“Œ {pos.capitalize()}:")
            definitions = m.get('definitions', [])
            for i, d in enumerate(definitions, 1):
                print(f" {i}. {d.get('definition', 'KhÃ´ng cÃ³')}")
                if d.get('vietnamese'):
                    print(f" â¡ï¸ {d['vietnamese']}")
                if d.get('example'):
                    print(f" ğŸ’¬ {d['example']}")
                if d.get('example_vietnamese'):
                    print(f" ğŸ’­ {d['example_vietnamese']}")
            print()
    print("\n" + "ğŸŒŸ" * 20 + "\n")

if __name__ == "__main__":
    username = ''
    password = ''
    token = get_token(username, password)
    if token:
        print("Nháº­p 'quit' hoáº·c nháº¥n Ctrl+C Ä‘á»ƒ thoÃ¡t.")
        while True:
            try:
                word = input("Nháº­p tá»« tiáº¿ng Anh cáº§n tra cá»©u: ").strip()
                if word.lower() in ['quit', 'exit']:
                    print("Táº¡m biá»‡t!")
                    break
                if word == '':
                    continue
                lookup_word(word, token)
            except KeyboardInterrupt:
                print("\nÄÃ£ thoÃ¡t chÆ°Æ¡ng trÃ¬nh. Táº¡m biá»‡t!")
                break
    else:
        print('KhÃ´ng láº¥y Ä‘Æ°á»£c token, khÃ´ng thá»ƒ tra cá»©u tá»«.')
