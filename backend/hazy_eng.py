import requests
from bs4 import BeautifulSoup

WIKTIONARY_API = "https://vi.wiktionary.org/w/api.php?action=query&format=json&prop=extracts&titles={word}"

# Danh sÃ¡ch cÃ¡c loáº¡i tá»« báº¡n muá»‘n tÃ¡ch ra (theo thá»© tá»± Æ°u tiÃªn)
PARTS_OF_SPEECH = {
    "TÃ­nh_tá»«": "TÃ­nh tá»«",
    "Danh_tá»«": "Danh tá»«",
    "Tráº¡ng_tá»«": "Tráº¡ng tá»«",
    "Äá»™ng_tá»«": "Äá»™ng tá»«",
    "Giá»›i_tá»«": "Giá»›i tá»«",
    "LiÃªn_tá»«": "LiÃªn tá»«",
    "Äáº¡i_tá»«": "Äáº¡i tá»«",
    "ThÃ¡n_tá»«": "ThÃ¡n tá»«",
    "PhÃ³_tá»«": "PhÃ³ tá»«",
    "Máº¡o_tá»«": "Máº¡o tá»«"
}

def fetch_wiktionary_entry(word):
    url = WIKTIONARY_API.format(word=word)
    response = requests.get(url)
    if response.status_code != 200:
        print("âš ï¸ KhÃ´ng thá»ƒ láº¥y dá»¯ liá»‡u tá»« Wiktionary.")
        return None
    return response.json()

def extract_pronunciation(soup):
    eng_section = soup.find("h2", {"data-mw-anchor": "Tiáº¿ng_Anh"})
    if not eng_section:
        return []

    ipa_list = []
    pron_heading = eng_section.find_next("h3", {"data-mw-anchor": "CÃ¡ch_phÃ¡t_Ã¢m"})
    if not pron_heading:
        return []

    ul = pron_heading.find_next("ul")
    if ul:
        for li in ul.find_all("li"):
            if "IPA" in li.text:
                ipa_text = li.find("span")
                if ipa_text:
                    ipa_list.append(ipa_text.text.strip())
    return ipa_list

def extract_part_sections(soup, part_map):
    results = {}
    eng_section = soup.find("h2", {"data-mw-anchor": "Tiáº¿ng_Anh"})
    if not eng_section:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y pháº§n Tiáº¿ng Anh.")
        return results

    # Duyá»‡t cÃ¡c pháº§n sau Tiáº¿ng Anh
    current_tag = eng_section.find_next_sibling()
    while current_tag:
        if current_tag.name == "h2":  # Káº¿t thÃºc pháº§n tiáº¿ng Anh
            break
        if current_tag.name == "h3":
            anchor = current_tag.get("data-mw-anchor")
            if anchor in part_map:
                part_label = part_map[anchor]
                meanings = []
                
                # Handle different possible structures
                ol_tag = current_tag.find_next("ol")
                p_tag = current_tag.find_next("p")
                
                # Case 1: Structure with <ol><li>...</li></ol>
                if ol_tag:
                    for li in ol_tag.find_all("li", recursive=False):
                        meaning_text = ""
                        if li.contents:
                            # Get text content while preserving HTML formatting
                            meaning_text = ''.join(str(content) for content in li.contents if not hasattr(content, 'name') or content.name != 'dl').strip()
                            meaning_text = BeautifulSoup(meaning_text, 'html.parser').get_text().strip()
                        
                        examples = []
                        dl = li.find("dl")
                        if dl:
                            for dd in dl.find_all("dd"):
                                ex_text = dd.get_text(strip=True)
                                if ex_text:
                                    examples.append(ex_text)
                                    
                        if meaning_text or examples:  # Only add if there's meaningful content
                            meanings.append({
                                "meaning": meaning_text,
                                "examples": examples
                            })
                # Case 2: Structure with just <p> after h3
                elif p_tag and not ol_tag:
                    meaning_text = p_tag.get_text(strip=True)
                    if meaning_text:
                        meanings.append({
                            "meaning": meaning_text,
                            "examples": []
                        })
                
                if meanings:  # Only add to results if we found meanings
                    results[part_label] = meanings
                    
        current_tag = current_tag.find_next_sibling()
    return results

def lookup_word(word):
    data = fetch_wiktionary_entry(word)
    if not data:
        return

    page = next(iter(data["query"]["pages"].values()))
    if "extract" not in page:
        print("âŒ KhÃ´ng cÃ³ ná»™i dung tá»«.")
        return
    print(f"\nğŸ”¤ Tá»«: {word.upper()}")
    soup = BeautifulSoup(page["extract"], "html.parser")

    # PhÃ¡t Ã¢m
    ipa_list = extract_pronunciation(soup)
    if ipa_list:
        print("\nğŸ”Š PhÃ¡t Ã¢m (IPA):")
        for ipa in ipa_list:
            print(f" ğŸ“ {ipa}")

    # NghÄ©a chia theo loáº¡i tá»«
    results = extract_part_sections(soup, PARTS_OF_SPEECH)
    if not results:
        print("âŒ KhÃ´ng cÃ³ pháº§n loáº¡i tá»« nÃ o phÃ¹ há»£p.")
        return

    for part, meanings in results.items():
        print(f"\nğŸ“Œ {part}:")
        for i, m in enumerate(meanings, 1):
            print(f" {i}. {m['meaning']}")
            for ex in m["examples"]:
                print(f"    ğŸ’¬ {ex}")
    print("\n" + "ğŸŒŸ" * 20 + "\n")

if __name__ == "__main__":
    print("Nháº­p 'quit' hoáº·c nháº¥n Ctrl+C Ä‘á»ƒ thoÃ¡t.")
    while True:
        try:
            word = input("Nháº­p tá»« tiáº¿ng Anh cáº§n tra cá»©u: ").strip()
            if word.lower() in ['quit', 'exit']:
                print("Táº¡m biá»‡t!")
                break
            if word == '':
                continue
            lookup_word(word)
        except KeyboardInterrupt:
            print("\nÄÃ£ thoÃ¡t chÆ°Æ¡ng trÃ¬nh. Táº¡m biá»‡t!")
            break